{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code:\n",
    "#https://github.com/google-deepmind/graphcast.git\n",
    "# data:\n",
    "#https://console.cloud.google.com/storage/browser/dm_graphcast;tab=objects?prefix=&forceOnObjectsSortingFiltering=false\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# METAL:\n",
    "# Tausche jax zu jax-metal in setup.py von graphcast\n",
    "# compile dm-tree from source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import xarray\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('graphcast')\n",
    "from graphcast import graphcast, checkpoint, normalization, autoregressive, casting, data_utils, rollout\n",
    "import jax\n",
    "import haiku as hk\n",
    "import numpy as np\n",
    "import functools\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"jax version: \", jax.__version__)\n",
    "print(\"jax devices: \", jax.devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## all\n",
    "import dataclasses\n",
    "import datetime\n",
    "import functools\n",
    "import math\n",
    "import re\n",
    "from typing import Optional\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "from graphcast import autoregressive\n",
    "from graphcast import casting\n",
    "from graphcast import checkpoint\n",
    "from graphcast import data_utils\n",
    "from graphcast import graphcast\n",
    "from graphcast import normalization\n",
    "from graphcast import rollout\n",
    "from graphcast import xarray_jax\n",
    "from graphcast import xarray_tree\n",
    "from IPython.display import HTML\n",
    "\n",
    "import haiku as hk\n",
    "import jax\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "import numpy as np\n",
    "import xarray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install ipywidgets\n",
    "#! pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "src_diffs_stddev_by_level = \"data/stats/diffs_stddev_by_level.nc\"\n",
    "src_mean_by_level = \"data/stats/mean_by_level.nc\"\n",
    "src_stddev_by_level = \"data/stats/stddev_by_level.nc\"\n",
    "\n",
    "with open(src_diffs_stddev_by_level, \"rb\") as f:\n",
    "    diffs_stddev_by_level = xarray.load_dataset(f).compute()\n",
    "with open(src_mean_by_level, \"rb\") as f:\n",
    "    mean_by_level = xarray.load_dataset(f).compute()\n",
    "with open(src_stddev_by_level, \"rb\") as f:\n",
    "    stddev_by_level = xarray.load_dataset(f).compute()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"data/params/GraphCast_ERA5_1979-2017_Resolution-0.25_PressureLevels-37_Mesh-2to6_PrecipitationInputOutput.npz\"\n",
    "with open(src, \"rb\",) as f:\n",
    "    ckpt = checkpoint.load(f, graphcast.CheckPoint)\n",
    "\n",
    "params = ckpt.params\n",
    "state = {}\n",
    "\n",
    "model_config = ckpt.model_config\n",
    "task_config = ckpt.task_config\n",
    "print(\"Model description:/n\", ckpt.description, \"/n\")\n",
    "print(\"Model license:/n\", ckpt.license, \"/n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch_src = \"data/datasets/source-era5_date-2022-01-01_res-0.25_levels-37_steps-01.nc\"\n",
    "with open(example_batch_src, \"rb\") as f:\n",
    "    example_batch = xarray.load_dataset(f).compute()\n",
    "\n",
    "eval_steps = 1\n",
    "eval_inputs, eval_targets, eval_forcings = data_utils.extract_inputs_targets_forcings(\n",
    "    example_batch, target_lead_times=slice(\"6h\", f\"{eval_steps*6}h\"),\n",
    "    **dataclasses.asdict(task_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch.total_precipitation_6hr.sel(lon=11.9, lat=51.5, method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example specific coordinates\n",
    "specific_lon = 12.0\n",
    "specific_lat = 51.5\n",
    "\n",
    "# Selecting the data for specific lon and lat in eval_inputs\n",
    "eval_inputs_specific = eval_inputs.sel(lon=specific_lon, lat=specific_lat, method='nearest')\n",
    "\n",
    "# Selecting the data for specific lon and lat in eval_targets\n",
    "eval_targets_specific = eval_targets.sel(lon=specific_lon, lat=specific_lat, method='nearest')\n",
    "\n",
    "# Selecting the data for specific lon and lat in eval_forcings\n",
    "eval_forcings_specific = eval_forcings.sel(lon=specific_lon, lat=specific_lat, method='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_forcings_specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_wrapped_graphcast(\n",
    "    model_config: graphcast.ModelConfig,\n",
    "    task_config: graphcast.TaskConfig):\n",
    "  \"\"\"Constructs and wraps the GraphCast Predictor.\"\"\"\n",
    "  # Deeper one-step predictor.\n",
    "  predictor = graphcast.GraphCast(model_config, task_config)\n",
    "\n",
    "  # Modify inputs/outputs to `graphcast.GraphCast` to handle conversion to\n",
    "  # from/to float32 to/from BFloat16.\n",
    "  predictor = casting.Bfloat16Cast(predictor)\n",
    "\n",
    "  # Modify inputs/outputs to `casting.Bfloat16Cast` so the casting to/from\n",
    "  # BFloat16 happens after applying normalization to the inputs/targets.\n",
    "  predictor = normalization.InputsAndResiduals(\n",
    "      predictor,\n",
    "      diffs_stddev_by_level=diffs_stddev_by_level,\n",
    "      mean_by_level=mean_by_level,\n",
    "      stddev_by_level=stddev_by_level)\n",
    "\n",
    "  # Wraps everything so the one-step model can produce trajectories.\n",
    "  predictor = autoregressive.Predictor(predictor, gradient_checkpointing=False)\n",
    "  return predictor\n",
    "\n",
    "\n",
    "\n",
    "def run_forward(model_config, task_config, inputs, targets_template, forcings):\n",
    "  predictor = construct_wrapped_graphcast(model_config, task_config)\n",
    "  return predictor(inputs, targets_template=targets_template, forcings=forcings)\n",
    "\n",
    "\n",
    "def grads_fn(params, state, model_config, task_config, inputs, targets, forcings):\n",
    "  def _aux(params, state, i, t, f):\n",
    "    (loss, diagnostics), next_state = loss_fn.apply(\n",
    "        params, state, jax.random.PRNGKey(0), model_config, task_config,\n",
    "        i, t, f)\n",
    "    return loss, (diagnostics, next_state)\n",
    "  (loss, (diagnostics, next_state)), grads = jax.value_and_grad(\n",
    "      _aux, has_aux=True)(params, state, inputs, targets, forcings)\n",
    "  return loss, diagnostics, next_state, grads\n",
    "\n",
    "# Jax doesn't seem to like passing configs as args through the jit. Passing it\n",
    "# in via partial (instead of capture by closure) forces jax to invalidate the\n",
    "# jit cache if you change configs.\n",
    "def with_configs(fn):\n",
    "  return functools.partial(\n",
    "      fn, model_config=model_config, task_config=task_config)\n",
    "\n",
    "# Always pass params and state, so the usage below are simpler\n",
    "def with_params(fn):\n",
    "  return functools.partial(fn, params=params, state=state)\n",
    "\n",
    "# Our models aren't stateful, so the state is always empty, so just return the\n",
    "# predictions. This is requiredy by our rollout code, and generally simpler.\n",
    "def drop_state(fn):\n",
    "  return lambda **kw: fn(**kw)[0]\n",
    "\n",
    "# Transform the function with Haiku\n",
    "run_forward = hk.transform_with_state(run_forward)\n",
    "\n",
    "init_jitted = jax.jit(with_configs(run_forward.init))\n",
    "\n",
    "#grads_fn_jitted = with_params(jax.jit(with_configs(grads_fn)))\n",
    "run_forward_jitted = drop_state(with_params(jax.jit(with_configs(\n",
    "    run_forward.apply))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Inputs:  \", eval_inputs.dims.mapping)\n",
    "print(\"Targets: \", eval_targets.dims.mapping)\n",
    "#print(\"Forcings:\", eval_forcings.dims.mapping)\n",
    "\n",
    "predictions = rollout.chunked_prediction(\n",
    "    run_forward_jitted,\n",
    "    rng=jax.random.PRNGKey(0),\n",
    "    inputs=eval_inputs,\n",
    "    targets_template=eval_targets * np.nan,\n",
    "    forcings=eval_forcings_specific)\n",
    "predictions\n",
    "# 10 min auf cpu windows\n",
    "# halle lan 51.5, lon 11.9\n",
    "\n",
    "# 11 min arm normales jax\n",
    "# 12 min arm metal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predictions: \", predictions.dims.mapping)\n",
    "print(\"PREDICIONT: \", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For NetCDF format\n",
    "predictions.to_netcdf('predicted_dataset.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the predicted dataset\n",
    "src = \"predicted_dataset.nc\"\n",
    "with open(src, \"rb\",) as f:\n",
    "    predicted_dataset = xarray.load_dataset(f).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predictions: \", predicted_dataset.dims.mapping)\n",
    "print(\"Predictions: \", predicted_dataset.dims)\n",
    "print(\"Predictions: \", predicted_dataset)\n",
    "\n",
    "# write the full print to a file\n",
    "sys.stdout = open('output.txt', 'w')\n",
    "print(\"Predictions: \", predicted_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total percipitation is not atmospheric, with pressure levels\n",
    "predicted_dataset_total_precipitation = predicted_dataset.total_precipitation_6hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_dataset_total_precipitation_halle = predicted_dataset_total_precipitation.sel(lon=11.9, lat=51.5, method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_dataset_total_precipitation_halle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_dataset_halle = predicted_dataset.sel(lat=51.5, lon=12.0, method='nearest')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predicted_dataset_halle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xarray_to_dataframe(dataset, variables=None, level=None, time=None, batch=None):\n",
    "    \"\"\"\n",
    "    Convert an xarray dataset to a pandas DataFrame.\n",
    "\n",
    "    :param dataset: xarray.Dataset\n",
    "    :param variables: List of variables to include in the DataFrame. If None, all variables are included.\n",
    "    :param level: Specific level to filter on. If None, includes all levels.\n",
    "    :param time: Specific time to filter on. If None, includes all times.\n",
    "    :param batch: Specific batch to filter on. If None, includes all batches.\n",
    "    :return: pandas.DataFrame\n",
    "    \"\"\"\n",
    "    # Select specific level, time, and batch if provided\n",
    "    if level is not None:\n",
    "        dataset = dataset.sel(level=level)\n",
    "    if time is not None:\n",
    "        dataset = dataset.sel(time=time)\n",
    "    if batch is not None:\n",
    "        dataset = dataset.sel(batch=batch)\n",
    "\n",
    "    # Select specific variables if provided\n",
    "    if variables is not None:\n",
    "        dataset = dataset[variables]\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = dataset.to_dataframe()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = xarray_to_dataframe(predicted_dataset, variables=None, level=None, time=None, batch=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df_total_precipitation_6hr = predictions_df['total_precipitation_6hr']\n",
    "# conert the series to dataframe\n",
    "predictions_df_total_precipitation_6hr = predictions_df_total_precipitation_6hr.to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df summary\n",
    "predictions_df_total_precipitation_6hr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort to lon and lat around halle saale lan 51.5 +-5, lon 11.9 +-5\n",
    "# so lat > 46.5 and lat < 56.5\n",
    "# and lon > 6.9 and lon < 16.9\n",
    "predictions_df_total_precipitation_6hr_halle = predictions_df_total_precipitation_6hr.loc[(predictions_df_total_precipitation_6hr['lat'] > 46.5) & (predictions_df_total_precipitation_6hr['lat'] < 56.5) & (predictions_df_total_precipitation_6hr['lon'] > 6.9) & (predictions_df_total_precipitation_6hr['lon'] < 16.9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make one df with exact lat=51.5 and lon=11.9\n",
    "predictions_df_total_precipitation_6hr_halle_exactly = predictions_df_total_precipitation_6hr.loc[(predictions_df_total_precipitation_6hr['lat'] == 51) & (predictions_df_total_precipitation_6hr['lon'] == 12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df_total_precipitation_6hr_halle_exactly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df_total_precipitation_6hr_halle.head()#.to_csv('predictions_df_total_precipitation_6hr_halle.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(predictions_df_total_precipitation_6hr['lon'], predictions_df_total_precipitation_6hr['lat'], c=predictions_df_total_precipitation_6hr['total_precipitation_6hr'], cmap='viridis')\n",
    "plt.colorbar(label='Total Precipitation (6hr)')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Heatmap of Total Precipitation on Longitude and Latitude')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot long lat\n",
    "predictions_df_total_precipitation_6hr.plot.scatter(x='lon', y='lat', c='total_precipitation_6hr', colormap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import IndexSlice as idx\n",
    "\n",
    "# Assuming 'lat' and 'lon' are part of a MultiIndex\n",
    "pred_germany_df = predictions_df.loc[idx[:, 47.3:55.1, 5.9:15.2, :, :], :]\n",
    "\n",
    "ger_xarray = pred_germany_df.to_xarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.to_csv('predictions_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_germany_df.to_csv('pred_germany_df_10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ge the column total_precipitation_6hr \n",
    "pred_germany_df_pre = pred_germany_df['total_precipitation_6hr']\n",
    "# conert the series to dataframe\n",
    "pred_germany_df_pre = pred_germany_df_pre.to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_germany_df_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# filter lon 9.5 to 13.5\n",
    "pred_germany_df_pre = pred_germany_df_pre[pred_germany_df_pre['lon'] > 9.5] \n",
    "pred_germany_df_pre = pred_germany_df_pre[pred_germany_df_pre['lon'] < 13.5]\n",
    "#pred_germany_df_pre.plot(x='lon', y='lat', kind='scatter')\n",
    "# plot lat lon and time\n",
    "pred_germany_df_pre[\"time\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "pred_germany_df_pre.plot(x='time', y='total_precipitation_6hr', figsize=(20,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Plotting functions\n",
    "\n",
    "def select(\n",
    "    data: xarray.Dataset,\n",
    "    variable: str,\n",
    "    level: Optional[int] = None,\n",
    "    max_steps: Optional[int] = None\n",
    "    ) -> xarray.Dataset:\n",
    "  data = data[variable]\n",
    "  if \"batch\" in data.dims:\n",
    "    data = data.isel(batch=0)\n",
    "  if max_steps is not None and \"time\" in data.sizes and max_steps < data.sizes[\"time\"]:\n",
    "    data = data.isel(time=range(0, max_steps))\n",
    "  if level is not None and \"level\" in data.coords:\n",
    "    data = data.sel(level=level)\n",
    "  return data\n",
    "\n",
    "def scale(\n",
    "    data: xarray.Dataset,\n",
    "    center: Optional[float] = None,\n",
    "    robust: bool = False,\n",
    "    ) -> tuple[xarray.Dataset, matplotlib.colors.Normalize, str]:\n",
    "  vmin = np.nanpercentile(data, (2 if robust else 0))\n",
    "  vmax = np.nanpercentile(data, (98 if robust else 100))\n",
    "  if center is not None:\n",
    "    diff = max(vmax - center, center - vmin)\n",
    "    vmin = center - diff\n",
    "    vmax = center + diff\n",
    "  return (data, matplotlib.colors.Normalize(vmin, vmax),\n",
    "          (\"RdBu_r\" if center is not None else \"viridis\"))\n",
    "\n",
    "def plot_data(\n",
    "    data: dict[str, xarray.Dataset],\n",
    "    fig_title: str,\n",
    "    plot_size: float = 5,\n",
    "    robust: bool = False,\n",
    "    cols: int = 4\n",
    "    ) -> tuple[xarray.Dataset, matplotlib.colors.Normalize, str]:\n",
    "\n",
    "  first_data = next(iter(data.values()))[0]\n",
    "  max_steps = first_data.sizes.get(\"time\", 1)\n",
    "  assert all(max_steps == d.sizes.get(\"time\", 1) for d, _, _ in data.values())\n",
    "\n",
    "  cols = min(cols, len(data))\n",
    "  rows = math.ceil(len(data) / cols)\n",
    "  figure = plt.figure(figsize=(plot_size * 2 * cols,\n",
    "                               plot_size * rows))\n",
    "  figure.suptitle(fig_title, fontsize=16)\n",
    "  figure.subplots_adjust(wspace=0, hspace=0)\n",
    "  figure.tight_layout()\n",
    "\n",
    "  images = []\n",
    "  for i, (title, (plot_data, norm, cmap)) in enumerate(data.items()):\n",
    "    ax = figure.add_subplot(rows, cols, i+1)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(title)\n",
    "    im = ax.imshow(\n",
    "        plot_data.isel(time=0, missing_dims=\"ignore\"), norm=norm,\n",
    "        origin=\"lower\", cmap=cmap)\n",
    "    plt.colorbar(\n",
    "        mappable=im,\n",
    "        ax=ax,\n",
    "        orientation=\"vertical\",\n",
    "        pad=0.02,\n",
    "        aspect=16,\n",
    "        shrink=0.75,\n",
    "        cmap=cmap,\n",
    "        extend=(\"both\" if robust else \"neither\"))\n",
    "    images.append(im)\n",
    "\n",
    "  def update(frame):\n",
    "    if \"time\" in first_data.dims:\n",
    "      td = datetime.timedelta(microseconds=first_data[\"time\"][frame].item() / 1000)\n",
    "      figure.suptitle(f\"{fig_title}, {td}\", fontsize=16)\n",
    "    else:\n",
    "      figure.suptitle(fig_title, fontsize=16)\n",
    "    for im, (plot_data, norm, cmap) in zip(images, data.values()):\n",
    "      im.set_data(plot_data.isel(time=frame, missing_dims=\"ignore\"))\n",
    "\n",
    "  ani = animation.FuncAnimation(\n",
    "      fig=figure, func=update, frames=max_steps, interval=250)\n",
    "  plt.close(figure.number)\n",
    "  return HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Choose predictions to plot\n",
    "\n",
    "\n",
    "# Set these variables manually as needed\n",
    "plot_pred_variable = \"2m_temperature\"  # example value, replace with your choice\n",
    "plot_pred_level = 500  # example value, replace with your choice\n",
    "plot_pred_robust = True  # set to True or False\n",
    "plot_pred_max_steps = predicted_dataset.dims['']  # or any integer value within the range\n",
    "\n",
    "# Information message\n",
    "print(\"Run the next cell to plot the predictions. Rerunning this cell clears your selection.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ger_xarray.dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of selecting data with multi-level indexing\n",
    "selected_data = predicted_dataset.isel(lon=0, lat=0, level=0, time=0, batch=0)\n",
    "precipitation_data = select(data=selected_data, variable=\"correct_variable_name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ger_total_precipitation_6hr = ger_xarray.total_precipitation_6hr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitation_data = select(data=ger_xarray, variable=\"total_precipitation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the predictions\n",
    "plot_data(\n",
    "    {f\"Predictions (lead time {i*6}h)\": select(predicted_dataset, \"precipitation\", max_steps=i+1)\n",
    "     for i in range(0, eval_steps)},\n",
    "    fig_title=\"Predictions\",\n",
    "    plot_size=5,\n",
    "    robust=True,\n",
    "    cols=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
