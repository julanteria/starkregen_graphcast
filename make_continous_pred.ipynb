{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import os\n",
    "import xarray\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('graphcast')\n",
    "from graphcast import graphcast, checkpoint, normalization, autoregressive, casting, data_utils, rollout\n",
    "import jax\n",
    "#jax.config.update('jax_platform_name', 'gpu')\n",
    "print(\"JAX is using: \", jax.devices())\n",
    "import haiku as hk\n",
    "import numpy as np\n",
    "import functools\n",
    "import time\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "src_diffs_stddev_by_level = \"data/stats/diffs_stddev_by_level.nc\"\n",
    "src_mean_by_level = \"data/stats/mean_by_level.nc\"\n",
    "src_stddev_by_level = \"data/stats/stddev_by_level.nc\"\n",
    "\n",
    "with open(src_diffs_stddev_by_level, \"rb\") as f:\n",
    "    diffs_stddev_by_level = xarray.load_dataset(f).compute()\n",
    "with open(src_mean_by_level, \"rb\") as f:\n",
    "    mean_by_level = xarray.load_dataset(f).compute()\n",
    "with open(src_stddev_by_level, \"rb\") as f:\n",
    "    stddev_by_level = xarray.load_dataset(f).compute()\n",
    "\n",
    "src = \"data/params/params_GraphCast_small - ERA5 1979-2015 - resolution 1.0 - pressure levels 13 - mesh 2to5 - precipitation input and output.npz\"\n",
    "with open(src, \"rb\",) as f:\n",
    "    ckpt = checkpoint.load(f, graphcast.CheckPoint)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "params = ckpt.params\n",
    "state = {}\n",
    "\n",
    "model_config = ckpt.model_config\n",
    "task_config = ckpt.task_config\n",
    "task_config = dataclasses.replace(task_config, input_duration=\"18h\")\n",
    "print(\"Model description:/n\", ckpt.description, \"/n\")\n",
    "print(\"Model license:/n\", ckpt.license, \"/n\")\n",
    "\n",
    "#example_batch_src = \"/Users/jules/Documents/github/starkregen_graphcast/data/datasets/source-era5_date-2022-01-01_res-0.25_levels-37_steps-01.nc\"\n",
    "#my_own_src = \"data/copernicus_data/input_pressure_and_no_pressure_combined_20_02.nc\"\n",
    "my_own_src = \"data/copernicus_data/input_pressure_and_no_pressure_combined_13_06.nc\"\n",
    "with open(my_own_src, \"rb\") as f:\n",
    "    example_batch = xarray.load_dataset(f).compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ckpt.task_config)\n",
    "# change input duration to 18h\n",
    "task_config = dataclasses.replace(task_config, input_duration=\"18h\")\n",
    "print(task_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the eval_inputs step=1\n",
    "eval_steps = 1\n",
    "eval_inputs, _, __ = data_utils.extract_inputs_targets_forcings(\n",
    "    example_batch, target_lead_times=slice(\"6h\", f\"{eval_steps*6}h\"), **dataclasses.asdict(task_config))\n",
    "\n",
    "\n",
    "\n",
    "# For eval_targets and eval_forcings step=x\n",
    "eval_steps = 10\n",
    "___, eval_targets, eval_forcings = data_utils.extract_inputs_targets_forcings(\n",
    "    example_batch, target_lead_times=slice(\"6h\", f\"{eval_steps*6}h\"), **dataclasses.asdict(task_config))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_targets.time.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#array([21600000000000, 43200000000000, 64800000000000],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_wrapped_graphcast(\n",
    "    model_config: graphcast.ModelConfig,\n",
    "    task_config: graphcast.TaskConfig):\n",
    "  \"\"\"Constructs and wraps the GraphCast Predictor.\"\"\"\n",
    "  # Deeper one-step predictor.\n",
    "  predictor = graphcast.GraphCast(model_config, task_config)\n",
    "\n",
    "  # Modify inputs/outputs to `graphcast.GraphCast` to handle conversion to\n",
    "  # from/to float32 to/from BFloat16.\n",
    "  predictor = casting.Bfloat16Cast(predictor)\n",
    "\n",
    "  # Modify inputs/outputs to `casting.Bfloat16Cast` so the casting to/from\n",
    "  # BFloat16 happens after applying normalization to the inputs/targets.\n",
    "  predictor = normalization.InputsAndResiduals(\n",
    "      predictor,\n",
    "      diffs_stddev_by_level=diffs_stddev_by_level,\n",
    "      mean_by_level=mean_by_level,\n",
    "      stddev_by_level=stddev_by_level)\n",
    "\n",
    "  # Wraps everything so the one-step model can produce trajectories.\n",
    "  predictor = autoregressive.Predictor(predictor, gradient_checkpointing=True)\n",
    "  return predictor\n",
    "\n",
    "\n",
    "\n",
    "def run_forward(model_config, task_config, inputs, targets_template, forcings):\n",
    "  predictor = construct_wrapped_graphcast(model_config, task_config)\n",
    "  return predictor(inputs, targets_template=targets_template, forcings=forcings)\n",
    "\n",
    "\n",
    "def grads_fn(params, state, model_config, task_config, inputs, targets, forcings):\n",
    "  def _aux(params, state, i, t, f):\n",
    "    (loss, diagnostics), next_state = loss_fn.apply(\n",
    "        params, state, jax.random.PRNGKey(0), model_config, task_config,\n",
    "        i, t, f)\n",
    "    return loss, (diagnostics, next_state)\n",
    "  (loss, (diagnostics, next_state)), grads = jax.value_and_grad(\n",
    "      _aux, has_aux=True)(params, state, inputs, targets, forcings)\n",
    "  return loss, diagnostics, next_state, grads\n",
    "\n",
    "# Jax doesn't seem to like passing configs as args through the jit. Passing it\n",
    "# in via partial (instead of capture by closure) forces jax to invalidate the\n",
    "# jit cache if you change configs.\n",
    "def with_configs(fn):\n",
    "  return functools.partial(\n",
    "      fn, model_config=model_config, task_config=task_config)\n",
    "\n",
    "# Always pass params and state, so the usage below are simpler\n",
    "def with_params(fn):\n",
    "  return functools.partial(fn, params=params, state=state)\n",
    "\n",
    "# Our models aren't stateful, so the state is always empty, so just return the\n",
    "# predictions. This is requiredy by our rollout code, and generally simpler.\n",
    "def drop_state(fn):\n",
    "  return lambda **kw: fn(**kw)[0]\n",
    "\n",
    "# Transform the function with Haiku\n",
    "run_forward = hk.transform_with_state(run_forward)\n",
    "\n",
    "init_jitted = jax.jit(with_configs(run_forward.init))\n",
    "\n",
    "#grads_fn_jitted = with_params(jax.jit(with_configs(grads_fn)))\n",
    "run_forward_jitted = drop_state(with_params(jax.jit(with_configs(\n",
    "    run_forward.apply))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start = time.time()\n",
    "predictions = rollout.chunked_prediction(\n",
    "    run_forward_jitted,\n",
    "    rng=jax.random.PRNGKey(0),\n",
    "    inputs=eval_inputs,\n",
    "    targets_template=eval_targets * np.nan,\n",
    "    forcings=eval_forcings,\n",
    "    num_steps_per_chunk=1,\n",
    "    verbose=True)\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predction finished in: \", end-start, \" s   or  \", (end-start)/60, \" min\")\n",
    "print(\"Predictions: \")\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For NetCDF format\n",
    "predictions.to_netcdf(f'possible_3_steps_predictions_13_06.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.time.values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
